{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "from mne.event import define_target_events\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import os\n",
    "import mne\n",
    "from mne.preprocessing import (ICA, create_eog_epochs, create_ecg_epochs,\n",
    "                               corrmap)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "\n",
    "T2M_sub_ids = [\n",
    "    'prex006','prex009','prex010','prex011','prex012',\n",
    "    'prex015','prex016','prex017','prex018','prex019','prex022','prex023',\n",
    "    'prex026','prex027','prex028'\n",
    "    ,'prex033','prex037','prex038','prex040',\n",
    "    'prex041','prex042','prex044','prex045',\n",
    "    'prex046','prex047','prex048','prex049','prex050','prex052',\n",
    "    'prex034','prex043','prex035'\n",
    "]\n",
    "#去掉了 5和9被试\n",
    "T1_sub_ids = [\n",
    "    'prex006M','prex009M','prex010M','prex011M','prex012M',\n",
    "    'prex015M','prex016M','prex017M','prex018M','prex019M','prex022M','prex023M',\n",
    "    'prex026M','prex027M','prex028M'\n",
    "    ,'prex033M','prex037M','prex038M','prex040S'\n",
    "    ,'prex041M','prex042M','prex044M','prex045M'\n",
    "    ,'prex046M','prex047M','prex048M','prex049S','prex050M','prex052M',\n",
    "    'prex034M','prex043M','prex035M'\n",
    "]\n",
    "\n",
    "T2S_sub_ids = [\n",
    "    'prex006S','prex009S','prex010S','prex011S','prex012S',\n",
    "    'prex015S','prex016S','prex017S','prex018S','prex019S','prex022S','prex023S',\n",
    "    'prex026S','prex027S','prex028S'\n",
    "    ,'prex033S','prex037S','prex038S','prex040M'\n",
    "    ,'prex041S','prex042S','prex044S','prex045S'\n",
    "    ,'prex046S','prex047S','prex048S','prex049M','prex050S','prex052S',\n",
    "    'prex034S','prex043S','prex035S'\n",
    "]\n",
    "data_path = 'E:\\Python LYW\\RSA\\spaced_learning\\pre10\\\\analysis\\data\\\\7evoked\\\\'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%导入数据\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex006M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 47 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-0.2, 0] sec)\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex009M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 44 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex010M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex011M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 46 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex012M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 44 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex015M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 47 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex016M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 49 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex017M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 46 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex018M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 49 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex019M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 45 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex022M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex023M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 47 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex026M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 46 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex027M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 39 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex028M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 42 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex033M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 46 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex037M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex038M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 49 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex040S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 43 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex041M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 49 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex042M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 43 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex044M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 46 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex045M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex046M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 43 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex047M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 44 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex048M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 43 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex049S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex050M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 49 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex052M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 49 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex034M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 44 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex043M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 45 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex035M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 47 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex006S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 46 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-0.2, 0] sec)\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex009S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 44 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex010S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex011S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex012S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 49 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex015S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 46 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex016S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 49 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex017S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex018S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 44 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex019S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex022S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 49 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex023S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 45 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex026S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 49 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex027S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex028S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 47 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex033S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 45 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex037S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 47 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex038S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 46 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex040M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex041S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex042S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 42 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex044S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 49 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex045S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex046S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 49 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex047S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex048S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex049M-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (102)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex050S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 43 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex052S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex034S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 45 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex043S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex035S-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (103)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 45 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex006-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 48 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-0.2, 0] sec)\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex009-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 39 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex010-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 35 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex011-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 33 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex012-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 32 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex015-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 43 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex016-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 43 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex017-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 41 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex018-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 35 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex019-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 38 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex022-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 46 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex023-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 40 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex026-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 42 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex027-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 33 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex028-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 28 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex033-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 38 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex037-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 41 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex038-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 47 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex040-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 36 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex041-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 50 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex042-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 33 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex044-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 40 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex045-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 41 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex046-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 39 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex047-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 42 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex048-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 32 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex049-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 38 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex050-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 47 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex052-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 46 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex034-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 43 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex043-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 36 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n",
      "Reading E:\\Python LYW\\RSA\\spaced_learning\\pre10\\analysis\\data\\7evoked\\prex035-ave.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms (101)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 40 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n"
     ]
    }
   ],
   "source": [
    "\n",
    "list_evoked_T1S = list()\n",
    "list_evoked_T2S = list()\n",
    "list_evoked_T2M = list()\n",
    "\n",
    "for sub_id in T1_sub_ids:\n",
    "    fname = data_path + sub_id + '-ave.fif'\n",
    "    evoked = mne.read_evokeds(fname)[0]\n",
    "    list_evoked_T1S.append(evoked)\n",
    "\n",
    "for sub_id in T2S_sub_ids:\n",
    "    fname = data_path + sub_id + '-ave.fif'\n",
    "    evoked = mne.read_evokeds(fname)[0]\n",
    "    list_evoked_T2S.append(evoked)\n",
    "\n",
    "for sub_id in T2M_sub_ids:\n",
    "    fname = data_path + sub_id + '-ave.fif'\n",
    "    evoked = mne.read_evokeds(fname)[0]\n",
    "    list_evoked_T2M.append(evoked)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#先考虑单个被试，单个channel的情况\n",
    "#选出对应的名字的channel\n",
    "\n",
    "# # 知道list的值，获取list的编号，用这个编号获取对应的data\n",
    "# evoked_01 = list_evoked_T1S[0]\n",
    "# ch_names = evoked_01.ch_names\n",
    "# print(ch_names.index('Cz'))\n",
    "# index = ch_names.index('Cz')\n",
    "# ch_data = evoked_01.data[index]\n",
    "#\n",
    "# # 怎么截取，就变成切片问题。需要考虑resolution\n",
    "# #  N400 取300到450之间\n",
    "# # （300+200）/2 = 250\n",
    "# #  (450+200)/2 = 325\n",
    "# ch_data_part = ch_data[250:325]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% 中介不管\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# 在上面基础上加入被试循环\n",
    "# 先对一个list下手 list_evoked_T1S\n",
    "\n",
    "# 想写成一个函数了。\n",
    "# list_ch_data_part  = []\n",
    "# for evoked_T1S in list_evoked_T1S:\n",
    "#     ch_names = evoked_T1S.ch_names\n",
    "#     print(ch_names.index('Cz'))\n",
    "#     index = ch_names.index('Cz')\n",
    "#     ch_data = evoked_T1S.data[index]\n",
    "#     ch_data_part = ch_data[250:325]\n",
    "#     list_ch_data_part.append(ch_data_part)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# 区域eeg赋值有了，考虑peak或者average，得到统计量的list\n",
    "# #\n",
    "# list_ch_mean_part = []\n",
    "# for ch_data_part in list_ch_data_part:\n",
    "#     ch_mean_part = ch_data_part.mean()\n",
    "#     list_ch_mean_part.append(ch_mean_part)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7392084461891413e-06\n",
      "-6.830361793989728e-07\n",
      "1.0527910692407465e-06\n",
      "1.1723218618338443e-07\n",
      "1.9524207400431453e-06\n",
      "1.3145252910700782e-06\n",
      "7.312137021064746e-07\n",
      "-3.67457909821774e-07\n",
      "3.2834836836596843e-06\n",
      "1.7040426973099195e-06\n",
      "8.515490907955428e-07\n",
      "4.901086904555456e-06\n",
      "1.636850155426284e-06\n",
      "7.018671978465974e-07\n",
      "6.616240378145203e-08\n",
      "1.2034379630832766e-06\n",
      "4.65369086691323e-06\n",
      "1.0442567955661644e-06\n",
      "1.6043779399170743e-06\n",
      "6.110355797619211e-08\n",
      "1.4241449001321504e-06\n",
      "1.5193592906991236e-06\n",
      "2.118760511360753e-06\n",
      "1.1620090010986634e-06\n",
      "6.67628814029222e-08\n",
      "2.161219942908635e-06\n",
      "9.334248398824752e-07\n",
      "2.706763498597513e-06\n",
      "4.4186879990822113e-07\n",
      "-5.152379895216965e-07\n",
      "-8.425436124564242e-08\n",
      "1.1406438713386786e-06\n",
      "4.140589069574535e-06\n",
      "-2.6537905619889717e-09\n",
      "-3.268218140945223e-08\n",
      "6.436870325352793e-07\n",
      "1.8918400323817936e-07\n",
      "1.4457376780109969e-06\n",
      "3.77751566846047e-07\n",
      "6.175604781554836e-07\n",
      "2.5895768216538504e-06\n",
      "2.025779757960095e-06\n",
      "1.576041197333196e-06\n",
      "3.962264826366433e-06\n",
      "1.1496097711962704e-06\n",
      "2.4340517228479284e-06\n",
      "3.080414600163533e-07\n",
      "1.6403169310023733e-06\n",
      "4.17819658874175e-06\n",
      "7.538022012798093e-07\n",
      "1.0801860564222515e-06\n",
      "-4.685445698456844e-08\n",
      "1.0836445978879353e-06\n",
      "1.827658421411211e-06\n",
      "2.3507614410071936e-06\n",
      "1.5939591568125491e-06\n",
      "6.562755007188731e-07\n",
      "2.5195517239629544e-06\n",
      "2.7787017511639067e-06\n",
      "3.357216136468768e-06\n",
      "5.232060806949524e-07\n",
      "5.497405443924881e-07\n",
      "3.1564772860520844e-07\n",
      "2.3162597589813225e-06\n",
      "3.8182874182519485e-06\n",
      "-7.621409373991054e-07\n",
      "4.050926577082298e-07\n",
      "7.478471632705148e-07\n",
      "3.91729219071491e-07\n",
      "1.406489733239075e-06\n",
      "4.652266507509565e-07\n",
      "-3.1378973896824485e-07\n",
      "2.131514546747652e-06\n",
      "9.636179791304283e-07\n",
      "5.135471539360483e-07\n",
      "3.639613692604535e-06\n",
      "1.2548750517329927e-06\n",
      "1.7472308051097837e-06\n",
      "1.167470356565749e-06\n",
      "2.5752429027695864e-07\n",
      "3.6542826381917312e-06\n",
      "1.3988079806886795e-07\n",
      "2.164711593165188e-06\n",
      "2.1055917845824436e-06\n",
      "9.011415047682951e-07\n",
      "1.3322462755945913e-06\n",
      "1.4731661632471095e-06\n",
      "4.188307866453428e-08\n",
      "1.8611114267590593e-07\n",
      "2.2371445926668243e-06\n",
      "2.0198303802480043e-06\n",
      "2.4004615546156505e-06\n",
      "-7.589246919762644e-07\n",
      "1.0571934784102791e-06\n",
      "3.4225361429035555e-07\n",
      "2.3391866873910057e-06\n"
     ]
    }
   ],
   "source": [
    "# 区域均值\n",
    "# 现在把所有条件的list都求出来。\n",
    "list_ch_data_part_T1S  = []\n",
    "for evoked in list_evoked_T1S:\n",
    "    ch_names = evoked.ch_names\n",
    "    index = ch_names.index('CPz')\n",
    "    ch_data = evoked.data[index]\n",
    "    ch_data_part = ch_data[350:400]\n",
    "    list_ch_data_part_T1S.append(ch_data_part)\n",
    "list_ch_mean_part_T1S = []\n",
    "for ch_data_part in list_ch_data_part_T1S:\n",
    "    #这里是求的均值\n",
    "    ch_mean_part = ch_data_part.mean()\n",
    "    list_ch_mean_part_T1S.append(ch_mean_part)\n",
    "\n",
    "list_ch_data_part_T2S  = []\n",
    "for evoked in list_evoked_T2S:\n",
    "    ch_names = evoked.ch_names\n",
    "    index = ch_names.index('CPz')\n",
    "    ch_data = evoked.data[index]\n",
    "    ch_data_part = ch_data[350:400]\n",
    "    list_ch_data_part_T2S.append(ch_data_part)\n",
    "list_ch_mean_part_T2S = []\n",
    "for ch_data_part in list_ch_data_part_T2S:\n",
    "    ch_mean_part = ch_data_part.mean()\n",
    "    list_ch_mean_part_T2S.append(ch_mean_part)\n",
    "\n",
    "list_ch_data_part_T2M  = []\n",
    "for evoked in list_evoked_T2M:\n",
    "    ch_names = evoked.ch_names\n",
    "    index = ch_names.index('CPz')\n",
    "    ch_data = evoked.data[index]\n",
    "    ch_data_part = ch_data[350:400]\n",
    "    list_ch_data_part_T2M.append(ch_data_part)\n",
    "list_ch_mean_part_T2M = []\n",
    "for ch_data_part in list_ch_data_part_T2M:\n",
    "    ch_mean_part = ch_data_part.mean()\n",
    "    list_ch_mean_part_T2M.append(ch_mean_part)\n",
    "f = open('./mean_data', 'w')\n",
    "\n",
    "for item in list_ch_mean_part_T1S:\n",
    "    print(item)\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.write(\"\\n\")\n",
    "for item in list_ch_mean_part_T2S:\n",
    "    print(item)\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.write(\"\\n\")\n",
    "for item in list_ch_mean_part_T2M:\n",
    "    print(item)\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=2.167983013265196, pvalue=0.037955338067114944)\n"
     ]
    }
   ],
   "source": [
    "# 写代码直接做ttest不是更方便？\n",
    "from scipy.stats import ttest_rel\n",
    "import pandas as pdc\n",
    "arr_ch_mean_part_T1S = np.array(list_ch_mean_part_T1S)\n",
    "arr_ch_mean_part_T2M = np.array(list_ch_mean_part_T2M)\n",
    "arr_ch_mean_part_T2S = np.array(list_ch_mean_part_T2S)\n",
    "\n",
    "print(ttest_rel((arr_ch_mean_part_T2S-arr_ch_mean_part_T1S),(arr_ch_mean_part_T2M-arr_ch_mean_part_T1S)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.936829932431484e-06\n",
      "-2.0661589895571054e-06\n",
      "1.8944480755532248e-08\n",
      "-1.1940784539217758e-07\n",
      "3.6671836461056373e-07\n",
      "1.0331576203745992e-06\n",
      "-8.846137593477684e-07\n",
      "-7.935428361646751e-08\n",
      "-2.581165556230022e-07\n",
      "-2.7703771096547442e-06\n",
      "-8.226777149309341e-07\n",
      "2.00816578663015e-06\n",
      "-7.437783662554144e-07\n",
      "1.0971835926977799e-06\n",
      "1.721459878539825e-07\n",
      "-3.329354562582143e-07\n",
      "1.0742487735119463e-06\n",
      "-1.0452471698275343e-06\n",
      "1.2122328779343872e-07\n",
      "1.2285064441383377e-06\n",
      "-4.452203550449578e-07\n",
      "-2.591428203648283e-06\n",
      "1.6720576490069944e-06\n",
      "-1.0600843937649392e-06\n",
      "-3.107287785414703e-07\n",
      "8.478743451556266e-08\n",
      "-4.313596442147139e-08\n",
      "1.1906171671462938e-06\n",
      "-2.259022619011217e-06\n",
      "-1.465483477668823e-06\n",
      "-1.3558128759665468e-06\n",
      "4.980722184522302e-08\n",
      "2.930005437524604e-06\n",
      "-3.2443910214679833e-06\n",
      "-7.227904569319423e-07\n",
      "-1.7290701892571502e-07\n",
      "-4.826037710763376e-07\n",
      "1.2801803868337403e-06\n",
      "-1.1565709600738576e-06\n",
      "-2.62553411904878e-07\n",
      "7.994574053539599e-07\n",
      "-1.9424125928930948e-06\n",
      "-1.1641833398916602e-06\n",
      "2.146682377471046e-06\n",
      "-6.747963639607983e-08\n",
      "2.7248368447942323e-07\n",
      "-1.5784979276414648e-06\n",
      "-3.2914866132411734e-07\n",
      "4.106508190289814e-08\n",
      "6.79976675329033e-08\n",
      "-1.445983183376473e-06\n",
      "-1.9331637592340072e-07\n",
      "8.915871281785833e-07\n",
      "-1.7155887945666167e-06\n",
      "1.6491018204932369e-06\n",
      "-2.3382665752343737e-07\n",
      "-1.3016621972623699e-06\n",
      "1.56637872866081e-06\n",
      "9.311262285842276e-07\n",
      "2.883705426253645e-06\n",
      "-1.2918532058081133e-06\n",
      "-1.977618223828628e-06\n",
      "-2.332554721048451e-06\n",
      "-7.251833375279635e-08\n",
      "2.895344957721437e-06\n",
      "-2.186814013683725e-06\n",
      "2.0865137484501618e-08\n",
      "-1.9552364683791837e-06\n",
      "5.449006120467416e-07\n",
      "1.1484061531659664e-06\n",
      "-3.076589974086209e-06\n",
      "-1.1004861499080696e-06\n",
      "1.5477144419107872e-06\n",
      "-1.3732981392423575e-07\n",
      "-9.926062523507977e-07\n",
      "3.520106891004098e-06\n",
      "-1.8772743994825426e-06\n",
      "5.142639642378532e-07\n",
      "-1.0322487623055744e-06\n",
      "2.1380649605180732e-07\n",
      "2.306722342649062e-06\n",
      "-1.554947198634413e-07\n",
      "-7.468841088093077e-07\n",
      "-1.0285446631784685e-06\n",
      "1.5402730698368337e-07\n",
      "-2.730411729076027e-06\n",
      "1.6813272191455915e-06\n",
      "-8.475729613443356e-08\n",
      "-2.562975434549834e-07\n",
      "-1.013731677275227e-07\n",
      "-1.1360973700119021e-07\n",
      "1.5949008467313025e-06\n",
      "-1.6126761933465662e-06\n",
      "-2.1505289944200436e-06\n",
      "-2.0057578084218544e-06\n",
      "-1.2876487936381068e-06\n"
     ]
    }
   ],
   "source": [
    "# 做一下峰值的比较\n",
    "\n",
    "list_ch_data_part_T1S  = []\n",
    "for evoked_T1S in list_evoked_T1S:\n",
    "    ch_names = evoked_T1S.ch_names\n",
    "    index = ch_names.index('CPz')\n",
    "    ch_data = evoked_T1S.data[index]\n",
    "    ch_data_part = ch_data[300:350]\n",
    "    list_ch_data_part_T1S.append(ch_data_part)\n",
    "list_ch_peak_part_T1S = []\n",
    "for ch_data_part in list_ch_data_part_T1S:\n",
    "    ch_peak_part = min(ch_data_part)\n",
    "    list_ch_peak_part_T1S.append(ch_peak_part)\n",
    "\n",
    "list_ch_data_part_T2S  = []\n",
    "for evoked_T1S in list_evoked_T2S:\n",
    "    ch_names = evoked_T1S.ch_names\n",
    "    index = ch_names.index('CPz')\n",
    "    ch_data = evoked_T1S.data[index]\n",
    "    ch_data_part = ch_data[300:350]\n",
    "    list_ch_data_part_T2S.append(ch_data_part)\n",
    "list_ch_peak_part_T2S = []\n",
    "for ch_data_part in list_ch_data_part_T2S:\n",
    "    ch_peak_part = min(ch_data_part)\n",
    "    list_ch_peak_part_T2S.append(ch_peak_part)\n",
    "\n",
    "list_ch_data_part_T2M  = []\n",
    "for evoked_T1S in list_evoked_T2M:\n",
    "    ch_names = evoked_T1S.ch_names\n",
    "    index = ch_names.index('CPz')\n",
    "    ch_data = evoked_T1S.data[index]\n",
    "    ch_data_part = ch_data[300:350]\n",
    "    list_ch_data_part_T2M.append(ch_data_part)\n",
    "list_ch_peak_part_T2M = []\n",
    "for ch_data_part in list_ch_data_part_T2M:\n",
    "    ch_peak_part = min(ch_data_part)\n",
    "    list_ch_peak_part_T2M.append(ch_peak_part)\n",
    "\n",
    "f = open('./peak_data', 'w')\n",
    "for item in list_ch_peak_part_T1S:\n",
    "    print(item)\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.write(\"\\n\")\n",
    "for item in list_ch_peak_part_T2S:\n",
    "    print(item)\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.write(\"\\n\")\n",
    "for item in list_ch_peak_part_T2M:\n",
    "    print(item)\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.close()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "17\n",
      "7\n",
      "75\n",
      "99\n",
      "12\n",
      "2\n",
      "40\n",
      "0\n",
      "13\n",
      "68\n",
      "63\n",
      "63\n",
      "57\n",
      "92\n",
      "25\n",
      "33\n",
      "78\n",
      "21\n",
      "0\n",
      "73\n",
      "28\n",
      "18\n",
      "73\n",
      "0\n",
      "66\n",
      "55\n",
      "28\n",
      "5\n",
      "52\n",
      "39\n",
      "18\n",
      "38\n",
      "27\n",
      "19\n",
      "55\n",
      "73\n",
      "31\n",
      "5\n",
      "43\n",
      "82\n",
      "0\n",
      "46\n",
      "56\n",
      "16\n",
      "57\n",
      "75\n",
      "18\n",
      "47\n",
      "89\n",
      "28\n",
      "8\n",
      "67\n",
      "30\n",
      "6\n",
      "89\n",
      "75\n",
      "16\n",
      "45\n",
      "4\n",
      "16\n",
      "45\n",
      "53\n",
      "23\n",
      "39\n",
      "12\n",
      "19\n",
      "85\n",
      "52\n",
      "28\n",
      "51\n",
      "38\n",
      "0\n",
      "1\n",
      "68\n",
      "37\n",
      "47\n",
      "99\n",
      "62\n",
      "23\n",
      "29\n",
      "91\n",
      "24\n",
      "16\n",
      "76\n",
      "35\n",
      "5\n",
      "28\n",
      "70\n",
      "52\n",
      "71\n",
      "24\n",
      "16\n",
      "86\n",
      "46\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# 潜伏期比较\n",
    "list_ch_data_part_T1S  = []\n",
    "for evoked_T1S in list_evoked_T1S:\n",
    "    ch_names = evoked_T1S.ch_names\n",
    "    index = ch_names.index('Cz')\n",
    "    ch_data = evoked_T1S.data[index]\n",
    "    ch_data_part = ch_data[250:350]\n",
    "    list_ch_data_part_T1S.append(ch_data_part)\n",
    "list_ch_peak_part_T1S = []\n",
    "for ch_data_part in list_ch_data_part_T1S:\n",
    "    ch_data_part = ch_data_part.tolist()\n",
    "    ch_peak_part = ch_data_part.index(min(ch_data_part))\n",
    "    list_ch_peak_part_T1S.append(ch_peak_part)\n",
    "\n",
    "list_ch_data_part_T2S  = []\n",
    "for evoked_T1S in list_evoked_T2S:\n",
    "    ch_names = evoked_T1S.ch_names\n",
    "    index = ch_names.index('Cz')\n",
    "    ch_data = evoked_T1S.data[index]\n",
    "    ch_data_part = ch_data[250:350]\n",
    "    list_ch_data_part_T2S.append(ch_data_part)\n",
    "list_ch_peak_part_T2S = []\n",
    "for ch_data_part in list_ch_data_part_T2S:\n",
    "    ch_data_part = ch_data_part.tolist()\n",
    "    ch_peak_part = ch_data_part.index(min(ch_data_part))\n",
    "    list_ch_peak_part_T2S.append(ch_peak_part)\n",
    "\n",
    "list_ch_data_part_T2M  = []\n",
    "for evoked_T1S in list_evoked_T2M:\n",
    "    ch_names = evoked_T1S.ch_names\n",
    "    index = ch_names.index('Cz')\n",
    "    ch_data = evoked_T1S.data[index]\n",
    "    ch_data_part = ch_data[250:350]\n",
    "    list_ch_data_part_T2M.append(ch_data_part)\n",
    "list_ch_peak_part_T2M = []\n",
    "for ch_data_part in list_ch_data_part_T2M:\n",
    "    ch_data_part = ch_data_part.tolist()\n",
    "    ch_peak_part = ch_data_part.index(min(ch_data_part))\n",
    "    list_ch_peak_part_T2M.append(ch_peak_part)\n",
    "\n",
    "f = open('./latency_data', 'w')\n",
    "for item in list_ch_peak_part_T1S:\n",
    "    print(item)\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.write(\"\\n\")\n",
    "for item in list_ch_peak_part_T2S:\n",
    "    print(item)\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.write(\"\\n\")\n",
    "for item in list_ch_peak_part_T2M:\n",
    "    print(item)\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# 想要把多个channel合并成一个再来比较。\n",
    "# 怎么合并呢，直接按某个维度进行压缩?求平均？\n",
    "\n",
    "#一个erp放进去，得到对应的channel平均\n",
    "def get_ROI(list_ROI_ch = ['Cz', 'CPz', 'Pz'], evoked = list_evoked_T1S[0]):\n",
    "    ch_names = evoked.ch_names\n",
    "    list_ROI_ch_data_part = []\n",
    "    for ROI_ch in list_ROI_ch:\n",
    "        index = ch_names.index(ROI_ch)\n",
    "        ch_data = evoked.data[index]\n",
    "        ch_data_part = ch_data[250:350]\n",
    "        list_ROI_ch_data_part.append(ch_data_part)\n",
    "    #制作对应的ndarray？还是直接全部相加，这样子倒是可以确定结构\n",
    "    ROI_ch_data_part = np.zeros(shape=(100,))\n",
    "    for i in range(len(list_ROI_ch)-1):\n",
    "        sum_ROI_ch_data_part = ROI_ch_data_part+list_ROI_ch_data_part[i]\n",
    "    ROI_ch_data_part = sum_ROI_ch_data_part/len(list_ROI_ch)\n",
    "    return ROI_ch_data_part\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'sum_ROI_ch_data_part' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\SILVER~1\\AppData\\Local\\Temp/ipykernel_6204/2182784091.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mlist_ch_data_part_T1S\u001B[0m  \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mevoked_T1S\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mlist_evoked_T1S\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m     \u001B[0mROI_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_ROI\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlist_ROI_ch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'CPz'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevoked\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mevoked_T1S\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m     \u001B[0mlist_ch_data_part_T1S\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mROI_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mlist_ch_mean_part_T1S\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\SILVER~1\\AppData\\Local\\Temp/ipykernel_6204/1339961683.py\u001B[0m in \u001B[0;36mget_ROI\u001B[1;34m(list_ROI_ch, evoked)\u001B[0m\n\u001B[0;32m     15\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlist_ROI_ch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[0msum_ROI_ch_data_part\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mROI_ch_data_part\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mlist_ROI_ch_data_part\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m     \u001B[0mROI_ch_data_part\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msum_ROI_ch_data_part\u001B[0m\u001B[1;33m/\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlist_ROI_ch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mROI_ch_data_part\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mUnboundLocalError\u001B[0m: local variable 'sum_ROI_ch_data_part' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#和前面的代码合并，生成多个被试的\n",
    "list_ch_data_part_T1S  = []\n",
    "for evoked_T1S in list_evoked_T1S:\n",
    "    ROI_data = get_ROI(list_ROI_ch = ['CPz'], evoked = evoked_T1S)\n",
    "    list_ch_data_part_T1S.append(ROI_data)\n",
    "list_ch_mean_part_T1S = []\n",
    "for ch_data_part in list_ch_data_part_T1S:\n",
    "    # ch_data_part = ch_data_part.tolist()\n",
    "    ch_mean_part = ch_data_part.mean()\n",
    "    list_ch_mean_part_T1S.append(ch_mean_part)\n",
    "\n",
    "#写出去\n",
    "f = open('./mean_data', 'w')\n",
    "\n",
    "for item in list_ch_mean_part_T1S:\n",
    "    print(item)\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.write(\"\\n\")\n",
    "\n",
    "\n",
    "list_ch_data_part_T2S  = []\n",
    "for evoked_T2S in list_evoked_T2S:\n",
    "    ROI_data = get_ROI(list_ROI_ch = ['CPz'], evoked = evoked_T2S)\n",
    "    list_ch_data_part_T2S.append(ROI_data)\n",
    "list_ch_mean_part_T2S = []\n",
    "for ch_data_part in list_ch_data_part_T2S:\n",
    "    # ch_data_part = ch_data_part.tolist()\n",
    "    ch_mean_part = ch_data_part.mean()\n",
    "    list_ch_mean_part_T2S.append(ch_mean_part)\n",
    "\n",
    "\n",
    "\n",
    "for item in list_ch_mean_part_T2S:\n",
    "    print(item)\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.write(\"\\n\")\n",
    "#和前面的代码合并，生成多个被试的\n",
    "list_ch_data_part_T2M  = []\n",
    "for evoked_T2M in list_evoked_T2M:\n",
    "    ROI_data = get_ROI(list_ROI_ch = ['CPz'], evoked = evoked_T2M)\n",
    "    list_ch_data_part_T2M.append(ROI_data)\n",
    "list_ch_mean_part_T2M = []\n",
    "for ch_data_part in list_ch_data_part_T2M:\n",
    "    # ch_data_part = ch_data_part.tolist()\n",
    "    ch_mean_part = ch_data_part.mean()\n",
    "    list_ch_mean_part_T2M.append(ch_mean_part)\n",
    "\n",
    "\n",
    "for item in list_ch_mean_part_T2M:\n",
    "    print(item)\n",
    "    f.write(\"%s\\n\" % item)\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}